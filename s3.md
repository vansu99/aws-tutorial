# S3

Even though each bucket is created in specific region, S3 names must be unique globally

## S3's Object is consists of the following:

- Key
- Value
- Version ID
- Metadata
- Subresources (Access Control Lists, Torrent)

## Data consistency work for S3:

- Read after Write consistency for PUTS of new Objects
- Eventual Consistency for overwrite PUTS and DELETES

## Features:

- Tiered Storage Available
- Lifecycle Management
- Versioning
- Encryption
- MFA Delete
- Access Control Lists and Bucket Policies
- can create up to 100 buckets per count by default
- object's size is from 0 bytes up to 5TB
- upload object > 100MB => should use multipart upload
- upload object > 5GB => must use multipart upload

## S3 Storage Classes (tier):

- S3 Standard (99.99% availability 99.999999999% durability )
- S3 - IA (Infrequently Accessed) (99.9% availability 99.999999999% durability)
- S3 One Zone - IA (99.5% availability 99.999999999% durability )
- S3 - Intelligent Tiering
- S3 Glacier (Minutes to hours) (99.99% availability 99.999999999% durability)
- S3 Glacier Deep Archive (12 hours can acceptable) (99.99% availability 99.999999999% durability)

## Charged ways:

- Storage
- Requests
- Storage Management Pricing (tier)
- Data Transfer Pricing
- Transfer Acceleration
- Cross Region Replication Pricing

## S3 LifeCycle Management:

- Automates moving your objects between the different storage tiers
- Can be used in conjunction with versioning
- Can be applied to current versions and previous versions

## Cross Region Replication:

- Versioning must be enabled on both the source and destination buckets
- Regions must be unique
- Files in an existing bucket are not replicated automatically (only when add a new file that new file was automatically replicated)
- All subsequent updated files will be replicated automatically
- Delete markers are not replicated
- Deleting individual versions or delete markers will not be replicated

## S3 Transfer Acceleration:

Instead of uploading directly to S3 bucket, user can use a distinct URL to upload directly to an edge location which will then transfer that file to S3.

![s3](https://github.com/minhntm/aws-solutions-architect-associate-certificate/raw/master/images/s3-transfer-acceleration.png)

## Access Point:

- Managing data access at scale for applications using shared data sets on S3
- Bucket can have hundreds of access points
- Can create an access point for your S3 bucket that grants access for groups of users or applications for your data lake. An Access Point could support a single user or application, or groups of users or applications, allowing separate management of each access point
